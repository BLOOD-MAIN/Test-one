const axios = require('axios');
const config = require('../config');
const { cmd } = require('../command');

/**
 * Sinhala AI chat command
 * Usage:
 *   .si <prompt>        -> Sinhala answer
 *   .siai <prompt>      -> same as .si
 */
cmd({
  pattern: 'si',
  alias: ['siai','ai-si'],
  react: 'ü©∏',
  desc: 'Sinhala AI assistant (OpenAI-compatible)',
  category: 'ai',
  filename: __filename
}, 
async (conn, mek, m, { body, args, reply, isCreator }) => {
  try {
    const prompt = (args && args.length ? args.join(' ') : '').trim();
    if (!prompt) return reply('‚ö†Ô∏è ‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª prompt ‡∂ë‡∂ö ‡∂Ø‡∑è‡∂±‡∑ä‡∂±. ‡∂ã‡∂Ø‡∑è: *.si ‡∂∏‡∂ß ‡∂Ω‡∑í‡∑Ä‡∑ä‡∑Ä‡∂∏‡∑ä ‡∂ö‡∑ô‡∂ß‡∑í‡∂∫‡∑ô‡∂±‡∑ä ‡∂ö‡∑í‡∂∫‡∂Ω‡∑è ‡∂Ø‡∑ô‡∂±‡∑ä‡∂±*');

    const apiKey = config.OPENAI_API_KEY;
    const baseURL = (config.OPENAI_BASE || 'https://api.openai.com/v1').replace(/\/+$/,'') + '/chat/completions';
    const model = config.AI_MODEL || 'gpt-4o-mini';
    if (!apiKey) {
      return reply('‚ùå OPENAI_API_KEY ‡∑É‡∑ô‡∂ß‡∑ä ‡∂ö‡∂ª‡∂Ω‡∑è ‡∂±‡∑ê‡∑Ñ‡∑ê. Heroku/Render env vars ‡∑Ä‡∂Ω OPENAI_API_KEY ‡∂ë‡∂ö add ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.');
    }

    const systemPrompt = config.AI_SINHALA_SYSTEM || '‡∂î‡∂∂ ‡∑É‡∑í‡∂±‡∑ä‡∑Ñ‡∂Ω‡∑ô‡∂±‡∑ä‡∂∏ ‡∂ö‡∂≠‡∑è ‡∂ö‡∂ª‡∂± AI ‡∂ã‡∂Ø‡∑Ä‡∑ä‡∂ö‡∑è‡∂ª‡∂∫‡∑ô‡∂ö‡∑ä.';

    const payload = {
      model,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: prompt }
      ]
    };

    const res = await axios.post(baseURL, payload, {
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      timeout: 60000
    });

    const text = res?.data?.choices?.[0]?.message?.content?.trim();
    if (!text) return reply('‚ö†Ô∏è AI ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª‡∂ö‡∑ä ‡∂Ω‡∑ê‡∂∂‡∑î‡∂±‡∑ö ‡∂±‡∑ê‡∑Ñ‡∑ê.');

    return reply(text);
  } catch (err) {
    console.error('SI AI ERROR:', err?.response?.data || err.message);
    return reply('‚ùå AI error. ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª: ' + (err?.response?.data?.error?.message || err.message));
  }
});
